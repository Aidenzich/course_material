{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 載入PyTorch套件\n",
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 確認 PyTorch 的版本\n",
    "print(\"PyTorch version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 確認是否有GPU裝置\n",
    "print(\"GPU-enabled installation? {}\".format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 載入numpy套件\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立張量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立具32-bit浮點數的張量\n",
    "t = torch.FloatTensor(2, 3)\n",
    "print(t, t.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 查看變數類型\n",
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 浮點數格式轉換\n",
    "t = t.float()     #轉換為32-bit浮點數的張量\n",
    "print(t)\n",
    "t = t.double()    #轉換為64-bit浮點數的張量\n",
    "print(t)\n",
    "t = t.byte()      #轉換為8-bit浮點數的張量\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立數值為0的張量\n",
    "t = torch.zeros(2, 3)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立數值為1的張量\n",
    "t_ones = torch.ones(2, 3)\n",
    "print(t_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立相同維度且數值為0的張量\n",
    "t_zeros = torch.zeros_like(t_ones)\n",
    "print(t_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立一個沒有被賦予數值的張量，然後填入數值5\n",
    "t_fives = torch.empty(2, 3).fill_(5)\n",
    "print(t_fives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立一個符合均勻分佈、數值為隨機0~1之間的張量\n",
    "t_random = torch.rand(2, 3)\n",
    "print(t_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立一個符合標準常態分佈(平均值為0且標準差為1)的張量\n",
    "t_normal = torch.randn(2, 3)\n",
    "print(t_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 從numpy轉換到torch張量\n",
    "a = np.array([1., 2., 3.])   #建立一個numpy array (np.float32)\n",
    "t = torch.tensor(a)          #轉換為張量\n",
    "\n",
    "print(\"NumPy array: {}, type: {}\".format(a, a.dtype))\n",
    "print(\"Torch tensor: {}, type: {}\".format(t, t.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 從torch張量轉回到numpy array\n",
    "t = t.numpy()\n",
    "print(\"NumPy array: {}, type: {}\".format(t, t.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 可以善用index指定取得張量內的數值\n",
    "t = torch.randn(2, 3)\n",
    "t[:,0]     #印出第一個column的數值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 張量運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 純數\n",
    "s = torch.tensor(42) #建立一個只有1個純數的張量\n",
    "print(s)\n",
    "s.item()             #印出張量數值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立不同張量\n",
    "\n",
    "x = torch.randn(1,3)     #Row vector\n",
    "print(\"Row vector {} with size {}\".format(x, x.size()))\n",
    "\n",
    "\n",
    "v = torch.randn(3,1)     #Column vector\n",
    "print(\"Column vector {} with size {}\".format(v, v.size()))\n",
    "\n",
    "\n",
    "A = torch.randn(3, 3)    #Matrix\n",
    "print(\"Matrix {} with size {}\".format(A, A.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 張量的計算\n",
    "u = torch.matmul(A, v)     #矩陣的乘法\n",
    "print(\"u: \", u)\n",
    "b = torch.randn(3,1)\n",
    "y = u + b                  #矩陣的加法\n",
    "print(\"y: \", y)\n",
    "z = torch.add(u, b)        #加法的部分也可以使用torch.add\n",
    "print(\"z: \", z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "             \n",
    "t.t()                   # transpose\n",
    "t.numel()               # number of elements in tensor\n",
    "t.nonzero()             # indices of non-zero elements\n",
    "t.view(-1, 2)           # reorganizes the tensor to these dimensions\n",
    "t.squeeze()             # removes size 1 dimensions\n",
    "t.unsqueeze(0)          # inserts a dimension\n",
    "\n",
    "# operations in the package\n",
    "torch.arange(0, 10)     # tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "torch.eye(3, 3)         # creates a 3x3 matrix with 1s in the diagonal (identity in this case)\n",
    "t = torch.arange(0, 3)\n",
    "torch.cat((t, t))       # tensor([0, 1, 2, 0, 1, 2])\n",
    "torch.stack((t, t))     # tensor([[0, 1, 2],\n",
    "                        #         [0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(2,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## row相加\n",
    "t.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## column相加\n",
    "t.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 轉置\n",
    "t.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 計算張量內數值個數\n",
    "t.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新排列張量內數值\n",
    "t.view(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 張量增疊\n",
    "torch.stack((t, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在PyTorch上指定使用CPU或GPU的語法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立指定以GPU做運算的張量\n",
    "t_gpu = torch.randn(3, 3, device=\"cuda:0\")\n",
    "t_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立指定以CPU做運算的張量\n",
    "t = torch.randn(3, 3)   #也可以精準設置 torch.randn(3,3,device=\"cpu\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 把CPU處理的張量移至GPU\n",
    "t_gpu = t.to(\"cuda:0\")  # copies the tensor from CPU to GPU\n",
    "# note that if we do now t_to_gpu.to(\"cuda:0\") it will return the same tensor without doing anything else as this tensor already resides on the GPU\n",
    "print(t_gpu)\n",
    "print(t_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 如果有可用GPU時採用GPU cuda:0，若無則使用CPU\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以PyTorch建立簡單線性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 載入PyTorch神經網路套件\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型的超參數\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 亂數生成資料\n",
    "x_train = np.array(np.random.rand(15, 1), dtype=np.float32)\n",
    "y_train = np.array(np.random.rand(15, 1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 建立簡單線性模型\n",
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 損失函數與最佳化\n",
    "loss_function = nn.MSELoss()                                        #以mean-square error作為損失函數\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)   #利用stochastic gradient descent來最佳化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 訓練模型\n",
    "for epoch in range(num_epochs):\n",
    "    #將numpy array資料轉換為torch的張量\n",
    "    inputs = torch.from_numpy(x_train)\n",
    "    targets = torch.from_numpy(y_train)\n",
    "\n",
    "    #將資料傳入模型\n",
    "    outputs = model(inputs)\n",
    "    #計算loss數值\n",
    "    loss = loss_function(outputs, targets)\n",
    "    \n",
    "    #以反向傳播來做最佳化\n",
    "    optimizer.zero_grad()     #每次epoch都先初始化梯度\n",
    "    loss.backward()           #反向傳播最佳化loss\n",
    "    optimizer.step()          #利用stochastic gradient descent來最佳化模型\n",
    "    \n",
    "    #每訓練5次就印出現在的Epoch以及loss的數值\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 以matplotlib作圖\n",
    "predicted = model(torch.from_numpy(x_train)).detach().numpy()       #取得模型預測資料的數值\n",
    "plt.plot(x_train, y_train, 'ro', label='random data')               #畫出原始資料點\n",
    "plt.plot(x_train, predicted, label='Linear model')                  #畫出模型預測的線\n",
    "plt.legend()                                                        #顯示圖說\n",
    "plt.show()                                                          #顯示出圖來\n",
    "\n",
    "## 儲存訓練的模型\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
