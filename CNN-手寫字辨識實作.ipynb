{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch mnist 實例演練"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "程式執行時間約為\n",
    "\n",
    "- 141.72 sec (with GPU: GeForce GTX 860M)\n",
    "\n",
    "- 680.75 sec (with CPU: i5-4210H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先載入需要用的到套件\n",
    "\n",
    "from __future__ import print_function           # 導入Python新版本特性\n",
    "import numpy as np                              # 矩陣模組運算工具\n",
    "import matplotlib.pyplot as plt                 # 繪圖工具\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn                           # PyTorch的神經網路套件 (具參數調整)\n",
    "import torch.nn.functional as F                 # PyTorch的神經網路套件 (不具參數調整)\n",
    "import torch.optim as optim                     # PyTorch用作最佳化的套件\n",
    "import torchvision                              # PyTorch電腦視覺相關套件\n",
    "from torchvision import datasets, transforms    # PyTorch電腦視覺相關套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立CNN模型\n",
    "class Net(nn.Module):\n",
    "    # 我們這邊實作具兩層卷積層及兩層全連接層的CNN\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)    # 卷積層 1: nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)   # 卷積層 2: nn.Conv2d(in_channels, out_channels, kernel_size, stride=1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)      # 全連接層 1:　nn.Linear(in_features, out_features）\n",
    "        self.fc2 = nn.Linear(500, 10)          # 全連接層 2 (最後接上 10 類別分類):　nn.Linear(in_features, out_features）\n",
    "    \n",
    "    # 模型中的層傳遞\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))              # 對 input x 做 conv1 的 convolution 後以 ReLU 啟動函數進行處理\n",
    "        x = F.max_pool2d(x, 2, 2)              # 對接續的 x 做 2 * 2 的 max pooling\n",
    "        x = F.relu(self.conv2(x))              # 對接續的 x 做 conv2 的 convolution 後以 ReLU 啟動函數進行處理\n",
    "        x = F.max_pool2d(x, 2, 2)              # 對接續的 x 做 2 * 2 的 max pooling\n",
    "        x = x.view(-1, 4*4*50)                 # 改變張量維度 (flatten) 以接續全連接層\n",
    "        x = F.relu(self.fc1(x))                # 對接續的 x 做 fc1 全連接，並以ReLU啟動函數進行處理\n",
    "        x = self.fc2(x)                        # 對接續的 x 做 fc2 全連接，並以ReLU啟動函數進行處理\n",
    "        return F.log_softmax(x, dim=1)         # return softmax 函數作類別分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超參數區 (hyperparameters)\n",
    "# 本區參數可手動調整以最佳化模型\n",
    "\n",
    "batch_size = 64           # 進行一次批次訓練所使用的資料量\n",
    "test_batch_size = 1000    # 進行一次批次驗證所使用的資料量\n",
    "epochs = 10               # 訓練次數 = 10\n",
    "lr = 0.01                 # 模型的學習率\n",
    "momentum = 0.5            # 模型最佳化時用以調整學習率的參數\n",
    "log_interval = 10         # 每 10 次迭代就印出一次當前訓練狀態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定 torch 進行運算的裝置，如果有 cuda 就使用 GPU 進行運算，若無則使用 CPU 進行運算\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入手寫字辨識訓練資料\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data',\n",
    "                   train=True,                                              # 表示進行訓練 (訓練過程調整模型參數)\n",
    "                   download=True,                                           # 若之前無下載過 mnist，則會自動進行下載資料的動作\n",
    "                   transform=transforms.Compose([transforms.ToTensor()])),  # 表示將影像資料轉為張量進行運算\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入手寫字辨識驗證資料\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data',\n",
    "                   train=False,                                             # 表示進行驗證 (不調整模型參數)\n",
    "                   transform=transforms.Compose([transforms.ToTensor()])),  # 表示將影像資料轉為張量進行運算\n",
    "    batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義訓練過程\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # 開始訓練\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   # 從train_loader中取出batch的index, 資料, 以及資料的標籤\n",
    "        data, target = data.to(device), target.to(device)       # 指定不同變數之張量於運算的GPU或CPU裝置\n",
    "        optimizer.zero_grad()                # 模型初始化\n",
    "        output = model(data)                 # 將資料傳入模型\n",
    "        loss = F.nll_loss(output, target)    # 計算模型預測的答案與真實資料的誤差(negative log likelihood loss)\n",
    "        loss.backward()                      # 反向傳播\n",
    "        optimizer.step()                     # 調整模型內部參數\n",
    "        if batch_idx % log_interval == 0:    # print出該模型在epoch的訓練資料百分比以及loss數值\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義驗證過程\n",
    "def test(model, device, test_loader):\n",
    "    # 開始驗證\n",
    "    model.eval()\n",
    "    test_loss = 0    # 初始化loss\n",
    "    correct = 0      # 初始化預測正確數\n",
    "    with torch.no_grad():     #驗證過程不進行模型內部參數調整\n",
    "        for data, target in test_loader:                          # 從test_loader中取出資料以及資料的標籤\n",
    "            data, target = data.to(device), target.to(device)     # 指定不同變數之張量於運算的GPU或CPU裝置\n",
    "            output = model(data)                                  # 將資料傳入模型\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # 計算驗證過程的loss數值\n",
    "            pred = output.argmax(dim=1, keepdim=True)                        # 以模型預測的分數的指標位置去取得預測的答案(類別)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()            # 計算模型預測的正確率\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)                                    # 平均批次驗證的loss數值\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format( # print出loss數值及正確率\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)            # 將模型指定到GPU或CPU裝置進行運算\n",
    "# model = nn.DataParallel(model)    # 利用nn.DataParallel來使模型以多GPU進行運算\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)     # 使用stochastic gradient descent進行最佳化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以for迴圈進行訓練及驗證\n",
    "# range 的 epoch 數字要 +1\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader)\n",
    "\n",
    "torch.save(model.state_dict(),\"mnist_cnn.pt\") # 儲存訓練好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 接著取出一些手寫字辨識的影像來查看預測情況\n",
    "\n",
    "# 將test_loader的資料取出且以跟前面一樣的裝置做張量儲存\n",
    "examples = enumerate(test_loader)    \n",
    "batch_idx, (test_data, test_targets) = next(examples)\n",
    "test_data = test_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將資料傳入模型 (在此屬於驗證過程)\n",
    "with torch.no_grad():\n",
    "    output = model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以 matplotlib 做 3 * 3 的組合圖\n",
    "fig = plt.figure()\n",
    "for k in range(9):\n",
    "    plt.subplot(3,3,k+1)\n",
    "    plt.tight_layout()    # 優化組合圖排列\n",
    "    plt.imshow(test_data[k][0].cpu().numpy(), cmap='gray')                              # 以灰階影像顯示出每一張子圖\n",
    "    plt.title(\"Prediction: {}\".format(output.data.max(1, keepdim=True)[1][k].item()))   # 將預測的答案設為每個子圖的 title\n",
    "    plt.xticks([])        # 不顯示X座標軸刻度\n",
    "    plt.yticks([])        # 不顯示Y座標軸刻度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
